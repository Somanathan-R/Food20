{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - libwebp==1.2.4=h11a3e52_1\n",
      "  - protobuf==3.19.6=pypi_0\n",
      "  - libzopfli==1.0.3=he6710b0_0\n",
      "  - tensorflow-io-gcs-filesystem==0.31.0=pypi_0\n",
      "  - libcurl==7.88.1=h91b91d3_0\n",
      "  - pyasn1-modules==0.2.8=pypi_0\n",
      "  - pyyaml==6.0=py39h5eee18b_1\n",
      "  - gdk-pixbuf==2.42.10=h5eee18b_0\n",
      "  - numpy-base==1.23.5=py39h31eccc5_0\n",
      "  - pytz==2022.7=py39h06a4308_0\n",
      "  - tensorflow-estimator==2.10.0=pypi_0\n",
      "  - certifi==2022.12.7=py39h06a4308_0\n",
      "  - libgcc-ng==11.2.0=h1234567_1\n",
      "  - charls==2.2.0=h2531618_0\n",
      "  - tensorboard-plugin-wit==1.8.1=pypi_0\n",
      "  - jpeg==9e=h166bdaf_1\n",
      "  - zstd==1.5.2=ha4553b6_0\n",
      "  - debugpy==1.5.1=py39h295c915_0\n",
      "  - markupsafe==2.1.2=pypi_0\n",
      "  - krb5==1.19.4=h568e23c_0\n",
      "  - pyzmq==19.0.2=py39hb69f2a1_2\n",
      "  - cfitsio==3.470=h5893167_7\n",
      "  - joblib==1.1.1=py39h06a4308_0\n",
      "  - python==3.9.16=h7a1cb2a_2\n",
      "  - cairo==1.16.0=hb05425b_4\n",
      "  - astunparse==1.6.3=pypi_0\n",
      "  - numpy==1.24.2=pypi_0\n",
      "  - tk==8.6.12=h1ccaba5_0\n",
      "  - cffi==1.15.1=py39h5eee18b_3\n",
      "  - bzip2==1.0.8=h7b6447c_0\n",
      "  - scipy==1.10.0=py39h14f4228_1\n",
      "  - google-pasta==0.2.0=pypi_0\n",
      "  - libiconv==1.16=h7f8727e_2\n",
      "  - opt-einsum==3.3.0=pypi_0\n",
      "  - cryptography==39.0.1=py39h9ce1e76_0\n",
      "  - libev==4.33=h7f8727e_1\n",
      "  - intel-openmp==2021.4.0=h06a4308_3561\n",
      "  - libxcb==1.15=h7f8727e_0\n",
      "  - brunsli==0.1=h2531618_0\n",
      "  - giflib==5.2.1=h36c2ea0_2\n",
      "  - ca-certificates==2023.01.10=h06a4308_0\n",
      "  - markdown==3.4.3=pypi_0\n",
      "  - grpcio==1.51.3=pypi_0\n",
      "  - libgd==2.3.3=h6a678d5_2\n",
      "  - fsspec==2023.3.0=py39h06a4308_0\n",
      "  - pydot==1.4.2=py39h06a4308_0\n",
      "  - charset-normalizer==3.1.0=pypi_0\n",
      "  - zeromq==4.3.4=h9c3ff4c_1\n",
      "  - bottleneck==1.3.5=py39h7deecbd_0\n",
      "  - libsodium==1.0.18=h36c2ea0_1\n",
      "  - h5py==3.8.0=pypi_0\n",
      "  - graphite2==1.3.14=h295c915_1\n",
      "  - tensorflow-cpu==2.10.0=pypi_0\n",
      "  - gobject-introspection==1.72.0=py39hbb6d50b_2\n",
      "  - mkl_random==1.2.2=py39h51133e4_0\n",
      "  - snappy==1.1.9=h295c915_0\n",
      "  - pyasn1==0.4.8=pypi_0\n",
      "  - pyopenssl==23.0.0=py39h06a4308_0\n",
      "  - brotli==1.0.9=h5eee18b_7\n",
      "  - lz4-c==1.9.4=h6a678d5_0\n",
      "  - poppler==22.12.0=h381b16e_0\n",
      "  - glib==2.69.1=he621ea3_2\n",
      "  - atk-1.0==2.36.0=ha1a6a79_0\n",
      "  - cachetools==5.3.0=pypi_0\n",
      "  - importlib-metadata==6.1.0=pypi_0\n",
      "  - gtk2==2.24.33=h73c1081_2\n",
      "  - expat==2.4.9=h6a678d5_0\n",
      "  - libgomp==11.2.0=h1234567_1\n",
      "  - nss==3.74=h0370c37_0\n",
      "  - scikit-learn==1.2.1=py39h6a678d5_0\n",
      "  - libffi==3.4.2=h6a678d5_6\n",
      "  - tornado==6.1=py39hb9d737c_3\n",
      "  - zfp==0.5.5=h295c915_6\n",
      "  - libtool==2.4.6=h6a678d5_1009\n",
      "  - imagecodecs==2021.8.26=py39hfcb8610_2\n",
      "  - numexpr==2.8.4=py39he184ba9_0\n",
      "  - rsa==4.9=pypi_0\n",
      "  - libssh2==1.10.0=h8f2d780_0\n",
      "  - libgfortran-ng==11.2.0=h00389a5_1\n",
      "  - mkl==2021.4.0=h06a4308_640\n",
      "  - pip==23.0.1=py39h06a4308_0\n",
      "  - zipp==3.15.0=pypi_0\n",
      "  - urllib3==1.26.15=pypi_0\n",
      "  - libgfortran5==11.2.0=h1234567_1\n",
      "  - icu==58.2=he6710b0_3\n",
      "  - libstdcxx-ng==11.2.0=h1234567_1\n",
      "  - poppler-data==0.4.11=h06a4308_1\n",
      "  - fribidi==1.0.10=h7b6447c_0\n",
      "  - zlib==1.2.13=h5eee18b_0\n",
      "  - libbrotlidec==1.0.9=h5eee18b_7\n",
      "  - lerc==3.0=h295c915_0\n",
      "  - blosc==1.21.3=h6a678d5_0\n",
      "  - keras==2.10.0=pypi_0\n",
      "  - openssl==1.1.1t=h7f8727e_0\n",
      "  - libdeflate==1.17=h5eee18b_0\n",
      "  - libnghttp2==1.46.0=hce63b2e_0\n",
      "  - ncurses==6.4=h6a678d5_0\n",
      "  - _openmp_mutex==5.1=1_gnu\n",
      "  - idna==3.4=py39h06a4308_0\n",
      "  - librsvg==2.54.4=h36cc946_3\n",
      "  - mkl_fft==1.3.1=py39hd3c417c_0\n",
      "  - libpng==1.6.39=h5eee18b_0\n",
      "  - brotli-bin==1.0.9=h5eee18b_7\n",
      "  - yaml==0.2.5=h7b6447c_0\n",
      "  - libuuid==1.41.5=h5eee18b_0\n",
      "  - libbrotlienc==1.0.9=h5eee18b_7\n",
      "  - requests-oauthlib==1.3.1=pypi_0\n",
      "  - absl-py==1.4.0=pypi_0\n",
      "  - libedit==3.1.20221030=h5eee18b_0\n",
      "  - pandas==1.5.2=py39h417a72b_0\n",
      "  - c-ares==1.19.0=h5eee18b_0\n",
      "  - freetype==2.10.4=h0708190_1\n",
      "  - requests==2.28.2=pypi_0\n",
      "  - boost-cpp==1.73.0=h7f8727e_12\n",
      "  - brotlipy==0.7.0=py39h27cfd23_1003\n",
      "  - libwebp-base==1.2.4=h5eee18b_1\n",
      "  - locket==1.0.0=py39h06a4308_0\n",
      "  - nspr==4.33=h295c915_0\n",
      "  - harfbuzz==4.3.0=hf52aaf7_1\n",
      "  - dask-core==2022.7.0=py39h06a4308_0\n",
      "  - werkzeug==2.2.3=pypi_0\n",
      "  - scikit-image==0.19.3=py39h6a678d5_1\n",
      "  - termcolor==2.2.0=pypi_0\n",
      "  - psutil==5.9.0=py39h5eee18b_0\n",
      "  - imageio==2.26.0=py39h06a4308_0\n",
      "  - pillow==9.4.0=py39h6a678d5_0\n",
      "  - libclang==16.0.0=pypi_0\n",
      "  - ninja==1.10.2=h06a4308_5\n",
      "  - pango==1.50.7=h05da053_0\n",
      "  - xz==5.2.10=h5eee18b_1\n",
      "  - fontconfig==2.14.1=h4c34cd2_2\n",
      "  - ld_impl_linux-64==2.38=h1181459_1\n",
      "  - pixman==0.40.0=h7f8727e_1\n",
      "  - graphviz==2.50.0=h1b29801_1\n",
      "  - gast==0.4.0=pypi_0\n",
      "  - lcms2==2.12=h3be6417_0\n",
      "  - openjpeg==2.4.0=h3ad879b_0\n",
      "  - libboost==1.73.0=h28710b8_12\n",
      "  - libbrotlicommon==1.0.9=h5eee18b_7\n",
      "  - readline==8.2=h5eee18b_0\n",
      "  - wheel==0.38.4=py39h06a4308_0\n",
      "  - networkx==2.8.4=py39h06a4308_1\n",
      "  - google-auth-oauthlib==0.4.6=pypi_0\n",
      "  - sqlite==3.41.1=h5eee18b_0\n",
      "  - gts==0.7.6=hb67d8dd_3\n",
      "  - tensorboard-data-server==0.6.1=pypi_0\n",
      "  - libtiff==4.5.0=h6a678d5_2\n",
      "  - libxml2==2.10.3=hcbfbd50_0\n",
      "  - flatbuffers==23.3.3=pypi_0\n",
      "  - jupyter_core==5.3.0=py39hf3d152e_0\n",
      "  - toolz==0.12.0=py39h06a4308_0\n",
      "  - oauthlib==3.2.2=pypi_0\n",
      "  - pywavelets==1.4.1=py39h5eee18b_0\n",
      "  - tensorflow-directml-plugin==0.4.0.dev230202=pypi_0\n",
      "  - tensorboard==2.10.1=pypi_0\n",
      "  - mkl-service==2.4.0=py39h7f8727e_0\n",
      "  - pcre==8.45=h295c915_0\n",
      "  - libaec==1.0.4=he6710b0_1\n",
      "  - ninja-base==1.10.2=hd09550d_5\n",
      "  - keras-preprocessing==1.1.2=pypi_0\n",
      "  - setuptools==65.6.3=py39h06a4308_0\n",
      "  - cytoolz==0.12.0=py39h5eee18b_0\n",
      "  - wrapt==1.15.0=pypi_0\n",
      "  - jxrlib==1.1=h7b6447c_2\n",
      "  - google-auth==2.16.3=pypi_0\n",
      "  - pysocks==1.7.1=py39h06a4308_0\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "  - https://conda.anaconda.org/conda-forge/win-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%conda install --file requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing tensorflow and creating datasets from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install -c conda-forge tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1400 images belonging to 20 classes.\n",
      "Found 600 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_data_dir = 'food20dataset/train_set'\n",
    "test_data_dir = 'food20dataset/test_set'\n",
    "img_width, img_height = 200, 150\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum width: 100\n",
      "Minimum height: 100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "train_data_dir = 'food20dataset/train_set'\n",
    "\n",
    "min_width = float('inf')\n",
    "min_height = float('inf')\n",
    "for dirpath, dirnames, filenames in os.walk(train_data_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            img = Image.open(os.path.join(dirpath, filename))\n",
    "            width, height = img.size\n",
    "            if width < min_width:\n",
    "                min_width = width\n",
    "            if height < min_height:\n",
    "                min_height = height\n",
    "\n",
    "print(\"Minimum width:\", min_width)\n",
    "print(\"Minimum height:\", min_height)\n",
    "num_classes = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somanathan\\AppData\\Local\\Temp\\ipykernel_5472\\391245141.py:16: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "43/43 [==============================] - 91s 2s/step - loss: 7.2634 - accuracy: 0.0556 - val_loss: 2.9745 - val_accuracy: 0.0816\n",
      "Epoch 2/7\n",
      "43/43 [==============================] - 85s 2s/step - loss: 2.8187 - accuracy: 0.1367 - val_loss: 2.6410 - val_accuracy: 0.2448\n",
      "Epoch 3/7\n",
      "43/43 [==============================] - 69s 2s/step - loss: 2.0679 - accuracy: 0.4174 - val_loss: 2.1526 - val_accuracy: 0.3611\n",
      "Epoch 4/7\n",
      "43/43 [==============================] - 96s 2s/step - loss: 1.0191 - accuracy: 0.7500 - val_loss: 1.9084 - val_accuracy: 0.4861\n",
      "Epoch 5/7\n",
      "43/43 [==============================] - 82s 2s/step - loss: 0.3975 - accuracy: 0.9313 - val_loss: 1.8603 - val_accuracy: 0.5191\n",
      "Epoch 6/7\n",
      "43/43 [==============================] - 90s 2s/step - loss: 0.1429 - accuracy: 0.9861 - val_loss: 1.9767 - val_accuracy: 0.5035\n",
      "Epoch 7/7\n",
      "43/43 [==============================] - 87s 2s/step - loss: 0.0578 - accuracy: 0.9985 - val_loss: 1.8299 - val_accuracy: 0.5260\n"
     ]
    }
   ],
   "source": [
    "# 7 epochs is only required for 100% accuracy\n",
    "num_epochs = 7\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: food\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: food\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(filepath='food')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.models.load_model('food')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food index and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_index = {\n",
    "    0:'biriyani',\n",
    "    1:'bisibelebath',\n",
    "    2:'butternaan',\n",
    "    3:'chaat',\n",
    "    4:'chappati',\n",
    "    5:'dhokla',\n",
    "    6:'dosa',\n",
    "    7:'gulab jamun',\n",
    "    8:'halwa',\n",
    "    9:'idly',\n",
    "    10:'kathi roll',\n",
    "    11:'meduvadai',\n",
    "    12:'noodles',\n",
    "    13:'paniyaram',\n",
    "    14:'poori',\n",
    "    15:'samosa',\n",
    "    16:'tandoori chicken',\n",
    "    17:'upma',\n",
    "    18:'vada pav',\n",
    "    19:'ven pongal'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "gulab jamun\n"
     ]
    }
   ],
   "source": [
    "# test image in same folder as notebook with name 'testSample.jpg'\n",
    "\n",
    "i = Image.open('testSample.jpg').resize((150,200))\n",
    "i = tf.keras.preprocessing.image.img_to_array(i)\n",
    "prediction = m.predict(tf.expand_dims(i, axis=0))[0]\n",
    "predicted_class_index = tf.argmax(prediction).numpy()\n",
    "print(food_index[predicted_class_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "04b340dd5f910059b9fc038fd68e087e0f5d50e9ab92777f11791752fdd6bf96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
